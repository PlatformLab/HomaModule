.TH HOMA 7 2019-02-15 "Homa" "Linux Programmer's Manual"
.SH NAME
homa \- Homa transport protocol
.SH SYNOPSIS
.nf
.B #include <sys/socket.h>
.B #include <netinet/in.h>
.B #include <homa.h>
.PP
.B homa_socket = socket(AF_INET, SOCK_DGRAM, IPPROTO_HOMA)
.fi
.SH DESCRIPTION
.PP
Homa is a network transport protocol for communication within a datacenter.
Its most important benefit is that if offers exceptionally low latency
for small messages, even in the presence of high network loads.
It also has several other advantages over TCP; for a full rationale,
see "Homa: A Receiver-Driven Low-Latency Transport Protocol Using 
Network Priorities,"
.I Proceedings of ACM SIGCOMM
.IR 2019 ,
pp. 221\(en235 (https://dl.acm.org/citation.cfm?id=3230564).
.PP
Homa differs from TCP in several respects.
First, it is message-oriented, whereas TCP is stream-oriented.
Homa is designed for request-response communication (also known as
remote procedure calls, or RPCs): a client sends a request message to
a server; the server processes the request and then returns a
response message.
Messages can be any length, up to a
limit of
.B HOMA_MAX_MESSAGE_LENGTH
bytes.
.PP
Homa is connectionless: once a socket has been opened, it
may be used to communicate with any number of peers.
The same socket may be used both for initiating requests as client
and for receiving requests as server.
A client may have any number of outstanding requests at the same
time, to any number of servers; concurrent requests may complete in
any order.
Homa maintains state only for active requests, so it is economical
in environments where each machine communicates
with a large number of other machines.
.PP
Homa delivers messages reliably and can recover from packet drops,
packet duplication, and other intermittent network failures.
When a client issues a request, Homa will ensure that the request
is received by the server and that the response is transmitted
back to the client.
A request fails only if Homa cannot maintain communication with the
Homa transport module on the server.
.PP
Under some (rare) conditions, a Homa server may receive the same request
multiple times.
Homa assumes that application-level software will perform duplicate detection,
if that is important for the application.
.PP
Home is intended for use between machines that are physically
close, so round-trip latencies are at most a few tens of microseconds.
Homa is not suitable for wide-area communication.
.PP
In order for Homa to achieve its low latency, network switches must be
configured to enable priority queues in output ports and to obey 3-bit
priority values specified as the high-order bits of the DSCP field in
IP packet headers.
Homa assumes that 8 priority levels are available, but it can be
configured to use fewer than this.
.SH BASIC USAGE
.PP
Most of the normal system calls for I/O, such as
.BR read "(2), " write "(2), " connect "(2), " listen "(2), and " accept (2),
are not supported by Homa.
Instead, Homa offers a set of library methods that support
message-oriented communication.
.PP
For an application to initiate requests as a client, it opens a Homa
socket as shown in
.B SYNOPSIS
above, then invokes
.BR homa_invoke (3).
This will send a request message and wait for the response to arrive.
Alternatively, the application can invoke
.BR homa_send (3)
to send a request, followed later by
.BR homa_recv (3)
to wait for the reply.
Multiple requests may be initiated concurrently before waiting for any
replies.
The responses will not necessarily be received in the same order that the
requests were sent.
.PP
To act as server, an application first opens a Homa socket and then
invokes
.BR bind (2)
to associate a server port number with the socket.
The port number must not already being used by another socket, and must
be less than
.B HOMA_MIN_CLIENT_PORT
(Homa automatically assigns a separate client port to each socket, which
is used for outgoing requests; client port numbers are greater than or
equal to
.BR HOMA_MIN_CLIENT_PORT ).
Once
.BR bind (2)
has completed successfully, the application can receive incoming
requests by invoking
.BR homa_recv (3).
For each request that it receives, the application must eventually
invoke
.BR homa_reply (3)
to send a response.
.PP
Server sockets can also be used to send outgoing requests as described
above for clients. If the same socket is used for both outgoing and
incoming requests, then
.BR homa_recv (3)
may return either a request or a response packet.
Requests and responses can be distinguished using the peer
port number returned by
.BR homa_recv (3).
.PP
The
.BR shutdown (2)
system call may be invoked on Homa sockets. It ignores the
.I how
argument and disables the socket,
so that it may no longer be used for either sending or receiving messages.
If any threads are blocked waiting on the socket, they will be unblocked
and their current operations will return
.BR ESHUTDOWN .
.SH SYSCTL PARAMETERS
.PP
Homa supports several parameters that can be set with
.B sysctl
to tune its behavior.
To access a particular parameter, prepend
.B .net.homa.
to the value shown below.
The parameters are also visible as files in the directory
.IR /proc/sys/net/homa .
Most of these parameters are intended only for use in Homa testing;
the default values should work fine in production. It's probably a
bad idea to change any of these unless you are sure you have made
detailed performance measurements to justify the change.
.TP
.I cutoff_version
(Read-only) The current version for unscheduled cutoffs; incremented
automatically when unsched_cutoffs is modified.
.TP
.IR dead_buffs_limit
When an RPC completes, Homa doesn't immediately free up the resources it used,
since this could delay the application (e.g. if there are lots of
packet buffers to free). Instead, Homa defers RPC "reaping" to a time
when it is less likely to impact application performance, and it performs
the reaping in small chunks (see
.IR reap_limit ).
However, under high-load conditions this could result
in an accumulation of dead RPCs. If the total number of packet buffers in
dead RPCs reaches the value of this parameter, then Homa reaps more
aggressively (which could impact application performance) until the number
of dead packet buffers drops below
.I dead_buffs_limit .
.TP
.IR flags
Individual bits can be set or cleared to control particular Homa behaviors.
If the
.B HOMA_FLAG_DONT_THROTTLE
bit is set, Homa will not throttle output transmissions; packets will
always be sent immediately. This could result in long transmit queues for
the NIC, which defeats part of Homa's SRPT scheduling mechanism.
.TP
.IR duty_cycle
Determines the maximum fraction of network bandwidth that a single RPC
will be allowed to consume, in units of one-thousandth (e.g., 500 means 50%).
The main reason for this parameter is that it also limits the fraction
of a core that can be consumed by NAPI processing for a single incoming
message. Without this limit, a large incoming message can completely
consume one core for NAPI, which starves user threads on that core and
can result in high tail latency for short messages served by those
threads.
.TP
.IR grant_fifo_fraction
When sending grants, Homa normally uses an SRPT policy, granting to the
message(s) with the fewest remaining bytes. This parameter can be
used to reserve some of the bandwidth for the oldest message,
in order to prevent very large messages from starving.
The value specifies the fraction of scheduled bandwidth that it reserves
for the oldest message, specified in thousandths (e.g., 100 means that 10%
of the bandwidth is for FIFO and 90% for SRPT). As of October 2020, a small
value can provide significant benefits for the largest messages under very high
loads, but for most loads its effect is negligible.
.TP
.IR grant_increment
An integer value; each grant issued by a Homa receiver will allow the sender
to transmit at least this many additional bytes. Larger values result in
fewer grant packets, which reduces overhead, but they also result in
greater buffer occupancy. Reducing
.I grant_increment
below the amount of data in a full-size packet has no impact: Homa always
transmits full-size packets.
.TP
.IR gro_policy
An integer value that determines how Homa processes incoming packets
at the GRO level. See code in homa_offload.c for more details.
.TP
.IR link_mbps
An integer value specifying the bandwidth of this machine's uplink to
the top-of-rack switch, in units of 1e06 bits per second.
.TP
.IR log_topic
This value always reads as 0. Writing a nonzero value will cause Homa to
log various state information to the system log, depending on the value.
For details on the recognized values, consult the Homa code.
.TP
.IR max_dead_buffs
This parameter is updated by Homa to reflect the largest number of packet
buffers occupied by dead (but not yet reaped) RPCs in a single socket at
a given time. It may be reset to zero to initiate a new calculation.
.TP
.IR max_gro_skbs
An integer value setting an upper limit on the number of buffers that
Homa will allow to accumulate at interrupt level before passing them
to the softirq handler. At one point there was a theory that a low value might
improve performance, but it doesn't seem to have any impact.
.TP
.IR max_gso_size
An integer value setting an upper limit on the size of an output packet,
before segmentation using GSO. The Linux networking layer already imposes
an upper limit; this configuration value can be used to reduce it further.
.TP
.IR max_nic_queue_ns
An integer value specifying a NIC queue length in units of nanoseconds
(how long it will take the existing packets in the queue
to be fully transmitted).
If the NIC queue is longer than this, Homa will wait to queue additional
packets until the queue length drops below this value.
This parameter is used to throttle the NIC output queue in order to
implement SRPT more accurately for outbound messages.
Once a packet has been queued in the NIC, Homa cannot schedule a
higher priority back in front of it; the longer the queue, the
longer the delay for a newly arriving high priority packet.
Lower values for this parameter reduce preemption lag and result in
a better approximation of SRPT, but the value must be high enough to
queue the next packet before
the NIC becomes idle; otherwise, output bandwidth will be lost.
.TP
.IR max_overcommit
An integer value setting an upper limit on the number of incoming
messages to which Homa will issue grants at any given time. Higher
numbers generally improve link bandwidth utilization, but can result
in more buffering and may affect tail latency if there are not many
priority levels available. Must be at least 1.
.TP
.IR max_sched_prio
(Read-only) An integer value specifying the highest priority level that Homa
will use for scheduled packets; priority levels larger than this
will be used for unscheduled packets.
This parameter is set automatically by Homa when
.I unsched_cutoffs
is modified.
.TP
.IR num_priorities
The number of priority levels that Homa will use; Homa will use this many
consecutive priority level starting with 0 (before priority mapping).
Must not be more than 8.
.TP
.IR pacer_fifo_fraction
When the pacer is choosing which message to transmit next, it normally picks
the one with the fewest remaining bytes. However, it occasionally chooses
the oldest message in order to prevent very large messages from starving.
This value determines how frequently it picks the oldest message, specified
in thousandths (e.g., 100 means that 10% of the time it picks the oldest).
As of October 2020, it is hard to find situations where this value matters;
however, under very extreme loads a small value does provide benefit for
the largest messages, when used with
.I grant_fifo_fraction.
.TP
.IR poll_usecs
When a thread waits for an incoming message, Homa first busy-waits for a
short amount of time before putting the thread to sleep. If a message arrives
during this time, a context switch is avoided and latency is reduced.
This parameter specifies how long to busy-wait, in microseconds.
.TP
.IR priority_map
Used to map the internal priority levels computed by Homa (which range
from 0 to
.IR num_priorities \(en1,
to external values. Entry
.IR i
contains the external priority level corresponding to internal level
.IR i .
Each value must be an integer less than 8.
.TP
.IR reap_limit
Homa tries to perform cleanup of dead RPCs at times when it doesn't have
other work to do, so that this cost doesn't impact applications. This
integer value specifies how many packet buffers Homa will free in a single
call to the reaper; larger values may make the reaper more efficient, but
they can also result in a larger delay for applications.
.TP
.IR resend_interval
An integer value specifying how frequently resend requests may be sent
to a given peer (regardless of how many RPCs are outstanding to that
peer). This is in units
of "ticks" (see 
.I resend_ticks
below). This value and
.I timeout_resends
should be chosen together.
.TP
.IR resend_ticks
An integer value specifying a number of "ticks", each of which corresponds
to one invocation of Homa's internal timer function, which runs every
millisecond.
Homa will begin issuing resend requests for an RPC once this many ticks have
elapsed without receiving expected data from the peer; the exact timing and
spacing of those requests is determined by
.IR resend_interval .
The original plan was to send the first resend request relatively quickly,
in order to minimize the delay caused by lost packets, then space out
additional resends to minimize extra work created for an already-overloaded
peer. However, as of October 2020, small values of
.IR resend_ticks
result in fairly frequent RPC restarts.  The problem is that a short message
can get detoured on the slow path through ksoftirq, so that it takes one or
more 4 ms time slices before it is processed by Homa. Meantime, with a low
value of
.IR resend_ticks ,
the client issues a RESEND. Since the message has not yet been processed on the
server, it sends UNKNOWN, causing the client to restart. A larger value of
.IR
resend_ticks
reduces the likelihood of restarts (but doesn't completely eliminate the
problem).
.TP
.IR rtt_bytes
An estimate of the number of bytes that can be transmitted on the wire
by a host in the time it takes that host to send a full-size packet to
another host and receive back a grant packet. Used by Homa to ensure
full network bandwidth utilization (or whatever is specified by the
.IR duty_cycle
parameter).
.TP
.IR throttle_min_bytes
An integer value specifying the smallest packet size subject to
output queue throttling.
Packets smaller than this will be immediately added to the NIC
queue without considering the queue length.
The rationale for this is that small packets are limited by CPU
overheads: there is no way that the CPU can generate
small packets fast enough to build up a queue at the NIC.
Bypassing the throttling mechanism improves efficiency.
This value can be set to 0 to force all packets to use the throttling
mechanism.
.TP
.I timeout_resends
An integer value specifying how long to wait before considering a peer
to be dead. If this many resend requests have been issued to a peer without
receiving any packets from the peer, then Homa will consider the peer
dead and abort all RPCs involving that peer with
.BR ETIMEDOUT .
.TP
.IR unsched_cutoffs
An array of 8 integer values. The nth element specifies the largest
message size, in bytes, for which priority level n will be used.
Starting with index 
.I max_prio
and working backwards, values should be monotonically increasing.
An entry greater than or equal to
.B HOMA_MAX_MESSAGE_LENGTH
indicates the last unscheduled priority; priorities lower than
this will be used for scheduled packets.
.TP
.IR verbose
An integer value; nonzero means that Homa will generate additional
log output.
.SH /PROC FILES
.PP
In addition to files for the configuration parameters described above,
Homa also supports the following files under
.IR /proc .
.TP
.IR /proc/net/homa_metrics
Reading this file will return a snapshot of various counters maintained
by Homa.
Each line contains three fields that describe one counter: the counter's
name, its value, and a comment explaining the meaning of the counter.
The counters are all cumulative and monotonically increasing (they are zeroed
when Homa starts, but never again after that).
To compute statistics over an interval, read this file once at the beginning of
the interval, a second time at the end of the interval, and compute the
difference between the two readings.
.IP
Most of the counters are computed separately for each core. The data for
each core is preceded by a line whose counter name is "core"; the value is
the core number for the following lines. A few counters appear before the first
"core" line: these are core-independent counters such as elapsed time.
.SH IOCTLS
.PP
Homa supports several
.BR ioctl (2)
calls, which are used to implement the Homa library methods.
These
.BR ioctl(2)
calls should not be invoked directly.
.SH SEE ALSO
.BR homa_invoke (3),
.BR homa_recv (3),
.BR homa_reply (3),
.BR homa_send (3)
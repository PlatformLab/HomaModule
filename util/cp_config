#!/usr/bin/python3

# Copyright (c) 2020-2026 Homa Developers
# SPDX-License-Identifier: BSD-2-Clause or GPL-2.0+

# This cperf benchmark measures Homa slowdown while varying one or more
# aspects of Homa's configuration (such as duty cycle).
# Type "cp_config --help" for documentation.

from cperf import *
from switch import *

load_info = [["w2", 3.2, 5], ["w3", 14, 10], ["w4", 20, 20], ["w5", 20, 30]]

parser = get_parser(description=
        'Measures slowdown as the configuraton is changed in various ways.',
        usage='%(prog)s [options]')
parser.add_argument('-c', '--config', dest='config',
        choices=['balance', 'buffers', 'busy_usecs', 'client_threads',
                'dctcp_buffers', 'defer_min_bytes', 'fifo', 'gbps',
                'gen2', 'gen3', 'grant_policy', 'gro_busy_usecs', 'load',
                'max_gro', 'max_gso', 'max_nic_queue', 'mtu', 'nic_backlog',
                'poll', 'ports', 'prios', 'receivers', 'repeat',
                'tcp_buffers', 'throttle', 'time', 'unsched_bytes'],
        required = True,
        help='Aspect of configuration to change')
options = parser.parse_args()
init(options)

if options.workload != "":
    load_info = [[options.workload, options.gbps, options.seconds]]

plot_max_y = 1000
specs = []
if options.config == 'balance':
    # Vary the load balancing policy
    specs.append({'exp_name': 'gen2default',
            'label': 'Gen2 Default',
            'lb': 'xl170_default'
            })
    specs.append({'exp_name': 'gen2',
            'label': 'Gen2',
            'lb': 'gen2'
            })
    specs.append({'exp_name': 'gen3',
            'label': 'Gen3',
            'lb': 'gen3'
            })
    specs.append({'exp_name': 'gen3_alt',
            'label': 'Gen3 Alt',
            'lb': 'gen3_alt'
            })
elif options.config == 'buffers':
    # Vary the amount of buffer space in the switch
    if not options.workload:
        load_info = [["w3", 14, 10], ["w4", 20, 20], ["w5", 20, 60]]
    # Specs will be filled in below (they are workload dependent).
    for mb in [10, 2.5, 2]:
        specs.append({'exp_name': 'bufs_%.1fM' % (mb),
                'label': '%.1f MB' % (mb),
                'switch_buffer': mb})
elif options.config == 'busy_usecs':
    # Vary the time threshold for considering a core busy and trying
    # to schedule work elsewhere
    for usecs in [0, 10, 20, 50, 100, 200]:
        specs.append({'exp_name': 'busy_%d' % (usecs),
                'label': 'busy_usecs %d' % (usecs),
                'sysctl': ['.net.homa.busy_usecs', usecs]
                })
elif options.config == 'client_threads':
    # Vary the client thread configuration
    for ports, receivers in [[3, 2], [3, 3], [3, 4], [2, 3], [2, 4], [1, 5]]:
        name = "%d ports %d rcvrs" % (ports, receivers)
        specs.append({'exp_name': "p%dr%d" % (ports, receivers),
                'label': "%d ports %d rcvrs" % (ports, receivers),
                'options': ['client_ports', ports,
                            'port_receivers', receivers]
                })
elif options.config == 'dctcp_buffers':
    # Use DCTCP, vary the amount of buffer space in the switch
    if not options.workload:
        load_info = [["w3", 14, 10], ["w4", 20, 20], ["w5", 20, 60]]
    plot_max_y = 10000
    for mb in [10, 1.2, 0.7]:
        specs.append({'exp_name': 'bufs_%.1fM' % (mb),
                'label': '%.1f MB' % (mb),
                'options': ['protocol', 'dctcp'],
                'sysctl': ['.net.ipv4.tcp_congestion_control', 'dctcp'],
                'switch_buffer': mb})
elif options.config == 'defer_min_bytes':
    # Vary the fraction of bandwidth reserved for the oldest message
    for value in [1000, 3000, 10000]:
        specs.append({'exp_name': 'defer_%d' % (value),
                'label': 'defer_min_bytes %d' % (value),
                'sysctl': ['.net.homa.defer_min_bytes', value]})
elif options.config == 'fifo':
    # Vary the fraction of bandwidth reserved for the oldest message
    for fifo in [0, 5, 10, 20]:
        specs.append({'exp_name': 'fifo_%d' % (fifo),
                'label': '%d%% FIFO' % (fifo),
                'sysctl': ['.net.homa.grant_fifo_fraction', fifo*10,
                           '.net.homa.pacer_fifo_fraction', fifo*10]})
elif options.config == 'gbps':
    # Vary the assumed link speed to increase headroom for the pacer
    # to avoid overcommitting the uplink.
    for gbps in [26, 25, 24, 23]:
        specs.append({'exp_name': 'gpbs_%d' % (gbps),
                'label': '%d Gbps' % (gbps),
                'sysctl': ['.net.homa.link_mbps', gbps*1000]
                })
elif options.config == 'gen2':
    # Try multiple variants of the Gen2 load balancing policy
    specs.append({'exp_name': 'gen2default',
            'label': 'Gen2 Default',
            'sysctl': ['.net.homa.gro_policy', 82],
            'rss': 'xl170_default'
            })
    specs.append({'exp_name': 'gen2',
            'label': 'Gen2',
            'sysctl': ['.net.homa.gro_policy', 16],
            'rss': 'gen2'
            })
    specs.append({'exp_name': 'gen2bypass',
            'label': 'Gen2+Bypass',
            'sysctl': ['.net.homa.gro_policy', 82],
            'rss': 'gen2'
            })
elif options.config == 'gen3':
    # Try multiple variants of the Gen3 load balancing policy
    specs.append({'exp_name': 'gen3',
            'label': 'Gen3',
            'sysctl': ['.net.homa.gro_policy', 128+66],
            'rss': 'gen3'
            })
    specs.append({'exp_name': 'gen3nobypass',
            'label': 'Gen3-Bypass',
            'sysctl': ['.net.homa.gro_policy', 128+66],
            'rss': 'gen3'
            })
    specs.append({'exp_name': 'gen3noshortbypass',
            'label': 'Gen3-ShortBypass',
            'sysctl': ['.net.homa.gro_policy', 128+64],
            'rss': 'gen3'
            })
    specs.append({'exp_name': 'gen3_alt',
            'label': 'Gen3 Alt',
            'sysctl': ['.net.homa.gro_policy', 128+66],
            'rss': 'gen3_alt'
            })
elif options.config == 'grant_policy':
    # Try different ways of computing grant sizes (window and max_incoming)
    specs.append({'exp_name': 'default',
            'label': 'default'})
    for max_incoming in [500]:
        specs.append({'exp_name': 'max_%d' % (max_incoming),
                'label': 'max_incoming %dK' % (max_incoming),
                'sysctl': ['.net.homa.window', 0,
                           '.net.homa.max_incoming', max_incoming*1000]})
elif options.config == 'gro':
    # Vary the GRO policy
    specs.append({'exp_name': 'gen2default',
            'label': 'Gen2 Default',
            'sysctl': ['.net.homa.gro_policy', 82],
            'rss': 'xl170_default'
            })
elif options.config == 'load':
    # Vary the network utilization.
    for gbps in [30, 40, 50, 60, 70]:
        name = "gbps%d" % (gbps)
        specs.append({'exp_name': name,
                'label': '%d Gbps' % (gbps),
                'options': ['gbps', gbps/2]
                })
elif options.config == 'max_gro':
    # Vary the number of skbs processed at once by GRO before forwarding
    # to SoftIRQ
    for count in [5, 10, 20, 100]:
        specs.append({'exp_name': 'max_gro_%d' % (count),
                'label': 'max_gro_skbs %d' % (count),
                'sysctl': ['.net.homa.max_gro_skbs', count]
                })
elif options.config == 'max_gso':
    # Vary the max_gso_size configuration parameter
    for count in [5000, 10000, 20000, 50000, 100000]:
        specs.append({'exp_name': 'max_gso_%d' % (count),
                'label': 'max_gso_size %d' % (count),
                'sysctl': ['.net.homa.max_gso_size', count]
                })
elif options.config == 'max_nic_queue':
    # Vary the limit on length of any individual NIC queue
    for usecs in [5, 10, 20, 40]:
        specs.append({'exp_name': 'nicq_%d' % (usecs),
                'label': 'max_nic_queue_usecs %d' % (usecs),
                'sysctl': ['.net.homa.max_nic_queue_usecs', usecs]})
elif options.config == 'mtu':
    # Vary the maximum packet size
    for length in [1500, 3000, 5000, 7000, 9000]:
        specs.append({'exp_name': 'mtu_%d' % (length),
                'label': 'MTU %d' % (length),
                'mtu': length
                })
elif options.config == 'nic_backlog':
    # Vary the limit on an NIC queue length
    for micros in [5, 10, 20, 100, 10000]:
        specs.append({'exp_name': 'nic_%d' % (micros),
                'label': 'nic queue %d us' % (micros),
                'sysctl': ['.net.homa.max_nic_est_backlog_usecs', micros]
                })
elif options.config == 'poll':
    # Vary the polling interval
    for poll in [0, 20, 30, 40, 50]:
        specs.append({'exp_name': 'poll_%d' % (poll),
                'label': 'poll %d us' % (poll),
                'sysctl': ['.net.homa.poll_usecs', poll]
                })
elif options.config == 'ports':
    # Vary the numbers of server and client ports
    for client, server in [[2, 2], [2, 3], [2, 4], [3, 3], [3, 2], [4, 2]]:
        name = "s%dc%d" % (server, client)
        specs.append({'exp_name': name,
                'label': name,
                'options': ['server_ports', server,
                            'client_ports', client]
                })
elif options.config == 'prios':
    # Vary the number of available priority levels
    for priority in [1, 2, 3, 8]:
        specs.append({'exp_name': 'prios_%d' % (priority),
                'label': '%d prios' % (priority),
                'sysctl': ['.net.homa.num_priorities', priority]})
elif options.config == 'receivers':
    # Vary the numbers of receiving threads per port on both client and server
    for threads in [2, 3, 4, 5]:
        specs.append({'exp_name': 'rcvrs_%d' % (threads),
                'label': '%d rcv threads' % (threads),
                'options': ['port_receivers', threads,
                            'port_threads', threads]
                })
elif options.config == 'repeat':
    # Runs the same test multiple times to test repeatability; must setup
    # the configuration by hand before running experiment.
    for i in range(1,6):
        specs.append({'exp_name': 'run%d' % (i),
                'label': 'Run %d' % (i)
                })
elif options.config == 'tcp_buffers':
    # Use TCP, vary the amount of buffer space in the switch
    if not options.workload:
        load_info = [["w3", 14, 10], ["w4", 20, 20], ["w5", 20, 60]]
    plot_max_y = 10000
    for mb in [13.2, 8, 3]:
        specs.append({'exp_name': 'bufs_%.1fM' % (mb),
                'label': '%.1f MB' % (mb),
                'options': ['protocol', 'tcp'],
                'sysctl': ['.net.ipv4.tcp_congestion_control', 'cubic'],
                'switch_buffer': mb})
elif options.config == 'throttle':
    # Vary the cuttoff for short messages that bypass the throttle mechanism
    for cutoff in [100, 200, 500, 1000]:
        specs.append({'exp_name': 'throttle_%d' % (cutoff),
                'label': 'throttle_min_bytes %d' % (cutoff),
                'sysctl': ['.net.homa.throttle_min_bytes', cutoff]
                })
elif options.config == 'time':
    # Vary the experiment running time
    for seconds in [10, 20, 30, 50, 100]:
        specs.append({'exp_name': "secs%d" % (seconds),
                'label': "%d seconds" % (seconds),
                'options': ['seconds', seconds]
                })
elif options.config == 'unsched_bytes':
    # Vary unsched_bytes
    for unsched in [40, 60, 80, 100, 120]:
        specs.append({'exp_name': 'unsched_%dk' % (unsched),
                'label': 'unsched_bytes %dk' % (unsched),
                'sysctl': ['.net.homa.unsched_bytes', unsched*1000]
                })

# Keys are parameter names, values are old values to restore.
old_values = {}
switch = None
if not options.plot_only:
    try:
        # For each workload, run a set of experiments with a different
        # configurations.
        for workload, bw, seconds in load_info:
            if options.config == 'buffers':
                if workload == "w5":
                    mbs = [10, 2.5, 2]
                else:
                    mbs = [10, 2.0, 1]
                specs = []
                for mb in mbs:
                    specs.append({'exp_name': 'bufs_%.1fM' % (mb),
                            'label': '%.1f MB' % (mb),
                        'switch_buffer': mb})

            for spec in specs:
                o = copy.deepcopy(options)
                o.workload = workload
                o.gbps = bw/2.0
                o.seconds = seconds
                exp_name = "%s_%s" % (spec['exp_name'], workload)
                if 'sysctl' in spec:
                    for i in range(0, len(spec['sysctl']), 2):
                        name = spec['sysctl'][i]
                        value = spec['sysctl'][i+1]
                        if name not in old_values:
                            old_values[name] = get_sysctl_parameter(name,
                                    options.nodes[0])
                        log("Setting %s = %s" % (name, value))
                        set_sysctl_parameter(name, value, options.nodes)
                if 'options' in spec:
                    for i in range(0, len(spec['options']), 2):
                        name = spec['options'][i]
                        value = spec['options'][i+1]
                        setattr(o, name, value)
                if 'switch_buffer' in spec:
                    if not switch:
                        switch = Switch()
                    mb = spec['switch_buffer']
                    log("Setting buffer limit to %.1f MB" % (mb))
                    switch.set_buffer_limit(mb)
                if 'mtu' in spec:
                    do_ssh(["config", "mtu", str(spec['mtu'])], options.nodes)
                if 'lb' in spec:
                    do_ssh(["config", "lb", spec['lb']], options.nodes)
                start_servers(exp_name, o.servers, o)
                run_experiment(exp_name, o.clients, o)
    except Exception as e:
        log(traceback.format_exc())

    for name, value in old_values.items():
        print("Restoring %s to %s" % (name, value))
        set_sysctl_parameter(name, value, options.nodes)
    log("Stopping nodes")
    stop_nodes()
    scan_logs()
if switch:
    log("Resetting buffer limit to 13.2 MB")
    switch.set_buffer_limit(13.2)
    switch.close
    switch = None

# Generate plots and reports
for workload, bw, seconds in load_info:
    # Generate slowdown plot.
    log("Generating slowdown plot for %s" % (workload))
    title = "%s, %d %s nodes, %.1f Gbps" % (workload.capitalize(),
            options.num_nodes, get_node_type(), bw)
    ax = start_plot_vs_msg_length(title, plot_max_y, "%s_%s" % (
            specs[0]['exp_name'], workload), y_label=" Slowdown")
    for spec in specs:
        exp_name = "%s_%s" % (spec['exp_name'], workload)
        plot_slowdown(ax, exp_name, "p99", spec['label'] + ' P99')
    for spec in specs:
        exp_name = "%s_%s" % (spec['exp_name'], workload)
        plot_slowdown(ax, exp_name, "p50", spec['label'] + ' P50')
    if workload == "w5":
        ax.legend(loc="upper right", prop={'size': 9})
    else:
        ax.legend(loc="upper left", prop={'size': 9})
    plt.tight_layout()
    plt.savefig("%s/reports/%s_%s.pdf" %
            (options.log_dir, options.config, workload))

    # Generate latency plot.
    log("Generating latency plot for %s" % (workload))
    title = "%s, %d %s nodes, %.1f Gbps" % (workload.capitalize(),
            options.num_nodes, get_node_type(), bw)
    ax = start_plot_vs_msg_length(title, [10, 10000], "%s_%s" % (
            specs[0]['exp_name'], workload), y_label=r'RTT (Âµsec)')
    for spec in specs:
        exp_name = "%s_%s" % (spec['exp_name'], workload)
        plot_histogram(ax, exp_name, "p99", spec['label'] + ' P99')
    for spec in specs:
        exp_name = "%s_%s" % (spec['exp_name'], workload)
        plot_histogram(ax, exp_name, "p50", spec['label'] + ' P50')
    ax.legend(loc="upper left", prop={'size': 9})
    plt.tight_layout()
    plt.savefig("%s/reports/%s_%s_rtt.pdf" %
            (options.log_dir, options.config, workload))

    # Generate CDF of small-message RTTs.
    log("Generating short message CDFs for %s" % (workload))
    title = "%s, %d %s nodes" % (workload.capitalize(), options.num_nodes,
            get_node_type())
    start_cdf_plot(title, 10, 0.99e05, 1e-05, "RTT (usecs)",
            "Cumulative Fraction of Short Messages")
    for spec in specs:
        exp_name = "%s_%s" % (spec['exp_name'], workload)
        x, y = get_short_cdf(exp_name)
        plt.plot(x, y, label=spec['label'])

    plt.legend(loc="upper right", prop={'size': 9})
    plt.savefig("%s/reports/%s_%s_cdfs.pdf" %
            (options.log_dir, options.config, workload))
